pbinom(5,10,1/2)
pbinom(6,10,1/2)
pbinom(7,10,1/2)
pbinom(8,10,1/2)
#3.3
binom.test(x = 176, n = 240, p = 1/2)
#3.4
z = -3.9226
p = 2*pnorm(-abs(z))
print(p)
#3.2
m = 176
n = 240
theta.hat = m/n
theta.0 = 1/2
z.0 = (theta.hat - theta.0) / sqrt(theta.0*(1-theta.0)/n)
p = 2*pnorm(-abs(z))
p
#3.2
m = 176
n = 240
theta.hat = m/n
theta.0 = 1/2
z.0 = (theta.hat - theta.0) / sqrt(theta.0*(1-theta.0)/n)
p = 2*pnorm(-abs(z.0))
p
#3.4
z = -3.9226
p = 2*pnorm(-abs(z))
print(p)
z.0 = (theta.hat - theta.0) / sqrt(theta.0*(1-theta.0)/n)
z.1 = 0.2333/0.0327
#3.2
m = 176
n = 240
theta.hat = m/n
theta.0 = 1/2
z.0 = (theta.hat - theta.0) / sqrt(theta.0*(1-theta.0)/n)
z.1 = 0.2333/0.0327
p = 2*pnorm(-abs(z.0))
p
#3.3
binom.test(x = 176, n = 240, p = 1/2)
#3.4
z = -3.9226
p = 2*pnorm(-abs(z))
print(p)
#3.2
m = 176
n = 240
theta.hat = m/n
theta.0 = 1/2
z.0 = (theta.hat - theta.0) / sqrt(theta.0*(1-theta.0)/n)
z.1 = 0.2333/0.0327
p = 2*pnorm(-abs(z.0))
p
z.1 = 0.2333/0.0327
z.1
#3.4
z = -3.9226
p = 2*pnorm(-abs(z))
print(p)
#2.1
calcP <- function(v,r) # function used to calculate the probability of each probability
# takes in the v and r variables as input
{
y <- c(0:25)
p = choose(y+r-1,y) * (r ** r) * (exp(v) + r)**(-r-y)*exp(y*v) # the formula used to calculate p
}
y <- c(0:25) # initialize y as a collection from 0 to 25
plot(y,calcP(0,1),type ='l', col = 'red', xlab = 'Number of tails', ylab ='Probability',
main = 'Plot of the negative binomial probability mass function') # plotting
lines(y,calcP(1,2),col = 'black')
lines(y,calcP(1.5,2), col = 'blue')
legend("topright", legend=c("v = 0, r = 1", "v = 1, r = 2", "v = 1.5, 2"),
col=c("red", "black", "blue"), lty=1:2, cex=0.8)
#3.2
m = 176 # number of successes
n = 240 # total number of test
theta.hat = m/n # the sample mean
theta.0 = 1/2 # the null hypothesis sample mean
z.0 = (theta.hat - theta.0) / sqrt(theta.0*(1-theta.0)/n) # the z score
p = 2*pnorm(-abs(z.0))
p
w <-c(9, 16, “monkey”)
w <-c(9, 16, "monkey")
class(w)
iris
i = iris
iris #
library(tree)
library(e1071)
library(ROCR)
library(rpart)
library(ggplot2)
#install.packages("gridExtra")
library("gridExtra") # used to arrange ggplots
#install.packages("adabag")
library(adabag)
install.packages("caret")
#install.packages("adabag")
library(adabag)
#install.packages("adabag")
library(adabag)
#install.packages("adabag")
library(caret)
library(adabag)
install.packages(c("bit", "blob", "boot", "broom", "bslib", "cachem", "callr", "checkmate", "class", "cli", "codetools", "colorspace", "cpp11", "crayon", "curl", "data.table", "dbplyr", "digest", "dplyr", "dtplyr", "evaluate", "fansi", "fastmap", "flexmix", "forcats", "foreign", "fs", "gargle", "glmnet", "googledrive", "googlesheets4", "gtable", "haven", "highr", "Hmisc", "hms", "htmltools", "httr", "igraph", "isoband", "jsonlite", "KernSmooth", "knitr", "lattice", "lubridate", "maps", "markdown", "MASS", "Matrix", "mclust", "mgcv", "modelr", "nlme", "nnet", "openssl", "processx", "ps", "purrr", "Rcpp", "RcppEigen", "readr", "readxl", "rmarkdown", "rpart", "sass", "spatial", "stringi", "survival", "sys", "tibble", "tidyverse", "tinytex", "utf8", "viridis", "viridisLite", "vroom", "waldo", "xfun", "xml2", "yaml"))
#install.packages("adabag")
library(caret)
library(adabag)
library(adabag)
#install.packages("adabag")
library(tibble)
library(adabag)
install.packages("tibble")
library(adabag)
install.packages("tibble")
library(adabag)
library(rpart)
library(adabag)
install.packages("adabag")
library(adabag)
library(caret)
library(tidyverse)
install.packages("tibble")
library(e1071)
library(ROCR)
library(rpart)
library(tree)
library(e1071)
library(ROCR)
library(rpart)
library(ggplot2)
#install.packages("gridExtra")
library("gridExtra") # used to arrange ggplots
#install.packages("adabag")
library(tibble)
library(adabag)
bagging
n = 10
s = seq(0,10)
alpha = 0
theta.hat = s + alpha/n + (2*alpha)
n = 10
s = seq(0,10)
alpha = 0.5
theta.hat = s + alpha/n + (2*alpha)
n = 10
s = seq(0,10)
alpha = 0
theta.hat = s + alpha/n + (2*alpha)
theta.hat
n = 10
s = seq(0,10)
alpha = 0.5
theta.hat = s + alpha/n + (2*alpha)
theta.hat
n = 10
s = seq(0,10)
alpha = 0
theta.hat = (s + alpha)/(n + 2*alpha)
theta.hat
n = 10
s = seq(0,10)
alpha = 0.5
theta.hat = (s + alpha)/(n + 2*alpha)
theta.hat
# Binomial risk function for smoothed estimator of proportion
# FIT3154 Studio 2
bin.risk <- function(alpha, n)
{
# Make a grid of true population proportion (theta) values
theta = seq(0,1,length.out=1e3)
# Evaluate the bias and variance at each true population parameter
bias = alpha*(2*theta-1)/(2*alpha+n)
var  = n*(1-theta)*theta/(2*alpha+n)^2
# Return the theta values and corresponding risks
rv = list()
rv$theta = theta
rv$risk = bias^2 + var
return(rv)
}
# Binomial risk function for smoothed estimator of proportion
# FIT3154 Studio 2
bin.risk <- function(alpha, n)
{
# Make a grid of true population proportion (theta) values
theta = seq(0,1,length.out=1e3)
# Evaluate the bias and variance at each true population parameter
bias = alpha*(2*theta-1)/(2*alpha+n)
var  = n*(1-theta)*theta/(2*alpha+n)^2
# Return the theta values and corresponding risks
rv = list()
rv$theta = theta
rv$risk = bias^2 + var
return(rv)
}
rv=bin.risk(alpha=0, n=10)
plot(rv$theta,rv$risk,type="l")
rv=bin.risk(alpha=1/2, n=10)
lines(rv$theta,rv$risk,col="red")
n = 10
s = seq(0,10)
alpha = sqrt(n)/2
theta.hat = (s + alpha)/(n + 2*alpha)
theta.hat
rv=bin.risk(alpha=0, n=10)
plot(rv$theta,rv$risk,type="l")
rv=bin.risk(alpha=1/2, n=10)
lines(rv$theta,rv$risk,col="red")
# theta at 0.5 is highest risk because the observation is
# going to be extremely random pr 50-50
rv=bin.risk(alpha=0, n=10)
plot(rv$theta,rv$risk,type="l")
rv=bin.risk(alpha=1/2, n=10)
lines(rv$theta,rv$risk,col="red")
rv=bin.risk(alpha=0, n=10)
lines(rv$theta, col = "green")
n = 10
s = seq(0,10)
alpha = sqrt(n)/2
theta.hat = (s + alpha)/(n + 2*alpha)
theta.hat
rv=bin.risk(alpha=0, n=10)
lines(rv$theta, col = "green")
lines(rv$theta, rv$risk, col = "green")
rv=bin.risk(alpha, n)
lines(rv$theta, rv$risk, col = "green")
# theta at 0.5 is highest risk because the observation is
# going to be extremely random pr 50-50
rv=bin.risk(alpha=0, n=10)
plot(rv$theta,rv$risk,type="l")
rv=bin.risk(alpha=1/2, n=10)
lines(rv$theta,rv$risk,col="red")
n = 10
s = seq(0,10)
alpha = sqrt(n)/2
theta.hat = (s + alpha)/(n + 2*alpha)
theta.hat
rv=bin.risk(alpha, n)
lines(rv$theta, rv$risk, col = "green")
n = 100
s = seq(0,10)
alpha = sqrt(n)/2
theta.hat = (s + alpha)/(n + 2*alpha)
theta.hat
rv=bin.risk(alpha, n)
lines(rv$theta, rv$risk, col = "blue")
rv=bin.risk(alpha=sqrt(n)/2, n=100)
lines(rv$theta,rv$risk,col="blue")
# theta at 0.5 is highest risk because the observation is
# going to be extremely random pr 50-50
rv=bin.risk(alpha=0, n=10)
plot(rv$theta,rv$risk,type="l")
rv=bin.risk(alpha=1/2, n=10)
lines(rv$theta,rv$risk,col="red")
n = 10
s = seq(0,10)
alpha = sqrt(n)/2
theta.hat = (s + alpha)/(n + 2*alpha)
theta.hat
rv=bin.risk(alpha, n)
lines(rv$theta, rv$risk, col = "green")
rv=bin.risk(alpha=sqrt(n)/2, n=100)
lines(rv$theta,rv$risk,col="blue")
rv=bin.risk(alpha=0, n=100)
plot(rv$theta,rv$risk,type="l")
rv=bin.risk(alpha=sqrt(n)/2, n=100)
lines(rv$theta,rv$risk,col="blue")
rv=bin.risk(alpha=0, n=100)
plot(rv$theta,rv$risk,type="l")
rv=bin.risk(alpha=1/2, n=100)
lines(rv$theta,rv$risk,col="red")
rv=bin.risk(alpha=sqrt(n)/2, n=100)
lines(rv$theta,rv$risk,col="blue")
sigma2 = 1
sigma2.hat = seq(0.1, 10, length.out=1e3)
kl = (1/2)*log(sigma2.hat/sigma2) + sigma2/2/sigma2.hat - 1/2
plot(sigma2.hat, kl, type="l")
4
sigma2 = 2
sigma2.hat = seq(0.1, 10, length.out=1e3)
kl = (1/2)*log(sigma2.hat/sigma2) + sigma2/2/sigma2.hat - 1/2
lines(sigma2.hat, kl, type="l", col = "red")
# Approximate risk using simulation
normal.kl.risk <- function(mu, sigma2, n, k = 0, m = 1e5)
{
# To store the KL divergences for each iteration of the simulation
kl = matrix(0, m, 1)
# Do 'm' iterations
for (i in 1:m)
{
# Generate a sample from our population, i.e., y1,...,yn ~ N(mu, sigma2)
y = rnorm(n, mean = mu, sd = sqrt(sigma2))
# Estimate mu and sigma2 from the sample
mu.hat = mean(y)
sigma2.hat = sum((y-mu.hat)^2) / (n-k)
# Compute KL divergence for these estimates
kl[i] = (1/2)*log(sigma2.hat/sigma2) + sigma2/2/sigma2.hat + (mu-mu.hat)^2/2/sigma2.hat - 1/2
}
# Average the KL divergences for the 'm' simulations to estimate the risk (average/expected loss)
return(mean(kl))
}
# Exact formula for the risk
normal.kl.risk.exact <- function(n, k=0)
{
return( (1/2)*(digamma((n-1)/2) + log(2/(n-k))) + (n+1)*(n-k)/2/(n-3)/n - 1/2 )
}
normal.kl.risk(mu=0,sigma2=1,n=10,k=0,m=1e6)
normal.kl.risk(mu=0,sigma2=1,n=10,k=1,m=1e6)
normal.kl.risk(mu=0,sigma2=1,n=10,k=2,m=1e6)
normal.kl.risk(mu=0,sigma2=1,n=10,k=3,m=1e6)
normal.kl.risk(mu=0,sigma2=1,n=10,k=4,m=1e6)
normal.kl.risk(mu=0,sigma2=1,n=10,k=5,m=1e6)
#2.6
normal.kl.risk.exact(n=100,k=0)
normal.kl.risk.exact(n=100,k=1)
#2.7
normal.kl.risk.exact(n=10,k=0)
normal.kl.risk.exact(n=10,k=1)
normal.kl.risk.exact(n=100,k=0)
normal.kl.risk.exact(n=100,k=1)
life
s = 10
cauchy1 = sqrt(exp(v))/(sqrt(s)*pi*(1+(exp(v)/s)))
s = 100
cauchy2 = sqrt(exp(v))/(sqrt(s)*pi*(1+(exp(v)/s)))
s = 1000
cauchy3 = sqrt(exp(v))/(sqrt(s)*pi*(1+(exp(v)/s)))
plot(cauchy1, type = 'l', xlim= c(0,25), xlab=v)
lines(cauchy2, col= 'red')
lines(cauchy3, col = 'blue')
legend(x="topright",legend=c("s = 10", "s = 100", 's=1000'),
fill = c("black","red","blue")
)
#Q1.9
v = seq(0,50,length.out = 100)
s = 10
cauchy1 = sqrt(exp(v))/(sqrt(s)*pi*(1+(exp(v)/s)))
s = 100
cauchy2 = sqrt(exp(v))/(sqrt(s)*pi*(1+(exp(v)/s)))
s = 1000
cauchy3 = sqrt(exp(v))/(sqrt(s)*pi*(1+(exp(v)/s)))
plot(cauchy1, type = 'l', xlim= c(0,25), xlab=v)
lines(cauchy2, col= 'red')
lines(cauchy3, col = 'blue')
legend(x="topright",legend=c("s = 10", "s = 100", 's=1000'),
fill = c("black","red","blue")
)
#2.1a
library(mgcv)
daily.case =  read.csv("daily.cases.10.weeks.2023.csv", stringsAsFactors = T)
setwd("D:/Desktop/R files/3154 Files")
#2.1a
library(mgcv)
daily.case =  read.csv("daily.cases.10.weeks.2023.csv", stringsAsFactors = T)
fit.gam = gam(Cases ~ s(Day) + Day.Of.Week, data=daily.case, method="REML", family=nb(link=log,theta=NULL))
fit.gam
summary(fit.gam)
#2.2
fit.gam.identity = gam(Cases ~ s(Day) + Day.Of.Week, data=daily.case, method="REML", family=nb(link=identity,theta=NULL))
summary(fit.gam.identity)
#2.3
plot(daily.case$Day, daily.case$Cases)
lines(daily.case$Day, exp(predict(fit.gam, daily.case)), col="red")
lines(daily.case$Day, predict(fit.gam.identity, daily.case), col="blue")
legend(x="topleft",legend=c("link log Gam", "link identity Gam"),
fill = c("red","blue")
)
#2.3
plot(daily.case$Day, daily.case$Cases, ylab= "cases", xlab = "days")
lines(daily.case$Day, exp(predict(fit.gam, daily.case)), col="red")
lines(daily.case$Day, predict(fit.gam.identity, daily.case), col="blue")
legend(x="topleft",legend=c("link log Gam", "link identity Gam"),
fill = c("red","blue")
)
#2.3
plot(daily.case$Day, daily.case$Cases, ylab= "cases", xlab = "days", main= "identityGam identity performances")
lines(daily.case$Day, exp(predict(fit.gam, daily.case)), col="red")
lines(daily.case$Day, predict(fit.gam.identity, daily.case), col="blue")
legend(x="topleft",legend=c("link log Gam", "link identity Gam"),
fill = c("red","blue")
)
# MSE for log-link
mean((exp(predict(fit.gam, daily.case)) - daily.case$Cases)^2)
# MSE for identity
mean((predict(fit.gam.identity, daily.case) - daily.case$Cases)^2)
func.2.6 =  function(y,X,beta0,beta,r){
ret_list = list()
n = length(y)
ret_list$negative.log.likelihood = -sum(lgamma(y+r)) + sum(lgamma(y+1)) + n*lgamma(r)- n*r*log(r) - sum(y)*beta0 - y%*%X%*%beta +
sum((y+r)*log(r+exp(beta0+rowSums(X%*%beta))))
ret_list$beta0 = -sum(y) + sum((y+r)*(exp(beta0+rowSums(X%*%beta))/(r+exp(beta0+rowSums(X%*%beta)))))
ret_list$betaj = c()
for (j in 1:length(beta)){
ret_list$betaj[length(ret_list$betaj)+1] = - sum(y*X[,j]) + sum((y+r)*(exp(beta0+rowSums(X%*%beta))/(r+exp(beta0+rowSums(X%*%beta)))))*X[,j]
}
return(ret_list)
}
# MSE for log-link
mean((exp(predict(fit.gam, daily.case)) - daily.case$Cases)^2)
# MSE for identity
mean((predict(fit.gam.identity, daily.case) - daily.case$Cases)^2)
#2.6
func.2.6 =  function(y,X,beta0,beta,r){
ret_list = list()
n = length(y)
ret_list$negative.log.likelihood = -sum(lgamma(y+r)) + sum(lgamma(y+1)) + n*lgamma(r)- n*r*log(r) - sum(y)*beta0 - sum(y*rowSums(X%*%beta)) +
sum((y+r)*log(r+exp(beta0+rowSums(X%*%beta))))
ret_list$beta0 = -sum(y) + sum((y+r)*(exp(beta0+rowSums(X%*%beta))/(r+exp(beta0+rowSums(X%*%beta)))))
ret_list$betaj = c()
for (j in 1:length(beta)){
ret_list$betaj= append(ret_list$betaj, (-sum(y*X[,j]) + sum(((y+r)*X[,j]*(exp(beta0+rowSums(X%*%beta))))/(r+exp(beta0+rowSums(X%*%beta))))))
}
return(ret_list)
}
